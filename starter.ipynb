{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Conv2D, Dense, MaxPool2D\n",
    "from keras import utils\n",
    "\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = \"../input/tryponet_set2.tar.gz/tryponet_set2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_Xy(path):\n",
    "    filenames0 = glob(path + \"norm/*.png\")\n",
    "    filenames1 = glob(path + \"trypo/*.png\")\n",
    "    X = np.zeros((len(filenames0) + len(filenames1), 256, 256, 3))\n",
    "    \n",
    "    y = np.zeros(len(filenames0) + len(filenames1))\n",
    "    y[len(filenames0):] = 1.\n",
    "    \n",
    "    print(path + \"norm/*.png\")\n",
    "    for i, filename in enumerate(filenames0):\n",
    "        X[i] = plt.imread(filename)\n",
    "        if i % 100 == 0:\n",
    "            print(i, end=\" \")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(path + \"trypo/*.png\")\n",
    "    for i, filename in enumerate(filenames1):\n",
    "        X[len(filenames0) + i] = plt.imread(filename)\n",
    "        if i % 100 == 0:\n",
    "            print(i, end=\" \")\n",
    "            \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def array_2d_to_image(array, autorescale=True):\n",
    "    assert array.min() >= 0\n",
    "    assert len(array.shape) in [2, 3]\n",
    "    if array.max() <= 1 and autorescale:\n",
    "        array = 255 * array\n",
    "    array = array.astype('uint8')\n",
    "    return Image.fromarray(array)\n",
    "\n",
    "def model_summary(model):\n",
    "    print(\"Model created successfully.\")\n",
    "    print(model.summary())\n",
    "    ctx.channel_send('n_layers', len(model.layers))\n",
    "    ctx.channel_send('n_parameters', model.count_params())\n",
    "\n",
    "categories = ['norm', 'trypo']\n",
    "\n",
    "class NeptuneCallback(Callback):\n",
    "    def __init__(self, x_test, y_test, images_per_epoch=-1):\n",
    "        \n",
    "        try:\n",
    "            ctx.channel_reset('Log-loss training')\n",
    "            ctx.channel_reset('Log-loss validation')\n",
    "            ctx.channel_reset('Accuracy training')\n",
    "            ctx.channel_reset('Accuracy validation')\n",
    "            ctx.channel_reset('false_predictions')\n",
    "        except:\n",
    "            pass\n",
    "        self.epoch_id = 0\n",
    "        self.images_per_epoch = images_per_epoch\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_id += 1\n",
    "\n",
    "        # logging numeric channels\n",
    "        ctx.channel_send('Log-loss training', self.epoch_id, logs['loss'])\n",
    "        ctx.channel_send('Log-loss validation', self.epoch_id, logs['val_loss'])\n",
    "        ctx.channel_send('Accuracy training', self.epoch_id, logs['acc'])\n",
    "        ctx.channel_send('Accuracy validation', self.epoch_id, logs['val_acc'])\n",
    "\n",
    "        # Predict the digits for images of the test set.\n",
    "        validation_predictions = self.model.predict_classes(self.x_test)\n",
    "        scores = self.model.predict(self.x_test)\n",
    "\n",
    "        # Identify the incorrectly classified images and send them to Neptune Dashboard.\n",
    "        image_per_epoch = 0\n",
    "        for index, (prediction, actual) in enumerate(zip(validation_predictions, self.y_test.argmax(axis=1))):\n",
    "            if prediction != actual:\n",
    "                if image_per_epoch == self.images_per_epoch:\n",
    "                    break\n",
    "                image_per_epoch += 1\n",
    "\n",
    "                ctx.channel_send('false_predictions', neptune.Image(\n",
    "                    name='[{}] {} X {} V'.format(self.epoch_id, categories[prediction], categories[actual]),\n",
    "                    description=\"\\n\".join([\n",
    "                        \"{:5.1f}% {} {}\".format(100 * score, categories[i], \"!!!\" if i == actual else \"\")\n",
    "                        for i, score in enumerate(scores[index])]),\n",
    "                    data=array_2d_to_image(self.x_test[index,:,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/tryponet_set2.tar.gz/tryponet_set2/train/norm/*.png\n",
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 7300 7400 7500 7600 7700 7800 7900 8000 8100 8200 8300 8400 8500 8600 8700 8800 8900 9000 9100 9200 9300 9400 9500 9600 9700 9800 9900 10000 \n",
      "\n",
      "../input/tryponet_set2.tar.gz/tryponet_set2/train/trypo/*.png\n",
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 "
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_Xy(base_path + \"train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = load_Xy(base_path + \"train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = utils.to_categorical(y_train, 2)\n",
    "Y_test = utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network definition\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(256, 256, 3)))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 196608)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 393218    \n",
      "=================================================================\n",
      "Total params: 393,218\n",
      "Trainable params: 393,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15884 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      " 992/1000 [============================>.] - ETA: 0s23s - loss: 5.9018 - acc: 0.6338 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      " 992/1000 [============================>.] - ETA: 0s24s - loss: 5.9018 - acc: 0.6338 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      " 992/1000 [============================>.] - ETA: 0s24s - loss: 5.9018 - acc: 0.6338 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      " 992/1000 [============================>.] - ETA: 0s24s - loss: 5.9018 - acc: 0.6338 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/5\n",
      " 992/1000 [============================>.] - ETA: 0s24s - loss: 5.9018 - acc: 0.6338 - val_loss: 8.0590 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f77f697e048>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          epochs=20,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          verbose=2,\n",
    "          callbacks=[NeptuneCallback(X_test, Y_test, images_per_epoch=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
